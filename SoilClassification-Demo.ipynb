{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Soil Classification: Tensorflow Model Evaluation\n",
    "#### An introduction to image classification and model interpretation in Tensorflow\n",
    "Peter Van Katwyk\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ___\n",
    "### Background:\n",
    "Classification of soils can be an extremely important skill in many different fields including geotechnical engineering, agricultural science, construction, and even the at-home gardening. While many classification schemes exist, a popular and intuitive way of classifying soils is based on soil grain size, such as gravel, silt, sand, etc. This is a rather simple way of looking at soil since there are firm cutoffs between each classification. For example, gravel is any grain over 2 mm in diameter, sand is between $\\frac{1}{16}$ mm to 2 mm, and silt/clay is smaller than $\\frac{1}{16}$ mm.  \n",
    "\n",
    "### Objective\n",
    "In this exercise, you will use computer vision to make a simple classification nodel of soils based on photos of gravel, sand, and silt. A convolutional neural network framework is provided below and will be used to complete the objective of the exercise. Your objective is to run several models, by changing key parameters such as the number of convolutional layers and the number of nodes in each convolutional layer within the CNN. Then, you will use the Keras callback Tensorboard to determine which model preformed best.\n",
    "# ___\n",
    "### Key Concepts:\n",
    "#### Data Augmentation\n",
    "Data Augmentation is a practice that is commonly used in image classification that enlarges the existing image dataset by augmenting the existing data. This augmentation is most commonly seen in operations like shifting the image, mirroring the image horizontally or vertically, zooming in on the image, and so on. These augmentations then create new images and thus enhance the number of images to train on. Since the dataset used in this exercise is my own, I did not take thousands of pictures and therefore it is a good idea to use data augmentation. Read more about this in a great article from Jason Brownlee seen here:\n",
    "https://machinelearningmastery.com/how-to-configure-image-data-augmentation-when-training-deep-learning-neural-networks/\n",
    "\n",
    "#### Convolutional Neural Network (CNN)\n",
    "A convolutional neural network (CNN) is a popular model for image classification. CNNs distinguish characteristics of an image by looping through the pixel values in an image and calculating the dot product of a those pixels with a filter \"kernel\" matrix. These kernel matrices help accentuate different aspects of the image such as vertical and horizontal lines, curvature, etc. For more information on the algorithm itself, see: https://www.youtube.com/watch?v=YRhxdVk_sIs. The example code seen in Part 2: Model Training is heavily commented for quick understanding of CNN model building.\n",
    "\n",
    "#### Model Callbacks\n",
    "Model callbacks in Tensorflow are tools that help store past model fits, analyze performance, and many more applications. See the documentation to learn about individual callbacks: https://www.tensorflow.org/api_docs/python/tf/keras/callbacks. In this case, we will be using Tensorboad, which enables visualization of model fitting metrics in an interactive way. Each model fit iteration will save a file called an event, which we will use in Part 3: Model Evaluation to determine which model is most effective in predicting soil type. These files can then be loaded into various programs (like Tensorboard) to look useful information for each run.\n",
    "# ___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Data Retrieval and Augmentation\n",
    "To start, change the directory strings below to match where you have downloaded the train and test. The data can be downloaded from this link:  \n",
    "- Train: https://drive.google.com/drive/folders/11wyib_0RIWSSHT8YPkaAM4_DfhShG9ei?usp=sharing\n",
    "- Validation: https://drive.google.com/drive/folders/1v0RYcQMp9vuVCh_38jj5hLNqWV2xAEJ_?usp=sharing  \n",
    "\n",
    "Also, create a folder called \"callbacks\" and change the path below to find that folder. This will be useful in Part 3 of the exercise.\n",
    "\n",
    "Then, run the two cells below to load the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, MaxPooling2D, Dropout, Conv2D, Flatten, Activation\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import time\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set filepaths for train directory, test directory folders, callback folder, and models folder.\n",
    "# Download the train and validation data from the folders linked above and make your own callbacks/models folders\n",
    "train_dir = r'C:/Users/Peter/Documents/ML Demo/train/'\n",
    "validation_dir = r'C:/Users/Peter/Documents/ML Demo/validation/'\n",
    "logdir = r'C:/Users/Peter/Documents/ML Demo/callbacks/'\n",
    "models_dir = r'C:/Users/Peter/Documents/ML Demo/models/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA RETRIEVAL & AUGMENTATION\n",
    "\n",
    "# Initiate the Image Data Generator\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale = 1./255,                 # rescales image\n",
    "    horizontal_flip = True,           # allows mirrored horizontal flip\n",
    "    zoom_range = 0.2,                 # allows differing zooms\n",
    "    rotation_range = 10,              # rotates photo\n",
    "    shear_range = 0.2,                # shears photo\n",
    "    height_shift_range = 0.1,         # shifts height of objects in photo\n",
    "    width_shift_range = 0.1           # shifts width of objects in photo\n",
    ")\n",
    "# Use the Image Data Generator above to flow in photos from the directory\n",
    "# Note that the subdirectories correspond the their respective classifications\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size = (128, 128),        # resizes images to 128 x 128 pixels\n",
    "    batch_size = 32,\n",
    "    class_mode = 'categorical',\n",
    ")\n",
    "\n",
    "# Do the same for validation data.\n",
    "val_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "validation_generator = val_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    target_size = (128 ,128),\n",
    "    batch_size = 32,\n",
    "    class_mode = 'categorical',\n",
    "    shuffle = False\n",
    ")\n",
    "\n",
    "# These lines above should have the data loaded in. The printed\n",
    "# message should say:\n",
    "# Found 263 images belonging to 3 classes.\n",
    "# Found 64 images belonging to 3 classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Model Training\n",
    "In this section you will use the example CNN code below and train multiple models with these parameters:\n",
    "- 1 convolutional layer, 0 dense layers, 32 nodes\n",
    "- 1 convolutional layer, 1 dense layer, 32 nodes\n",
    "- 1 convolutional layer, 0 dense layers, 64 nodes\n",
    "- 1 convolutional layer, 1 dense layer, 64 nodes\n",
    "\n",
    "Create a loop that will initiate and fit these four models. Make sure to format the name of each model according to the loop iteration settings and make sure you have your callbacks saving in the right location. Also, be sure to save the model on each iteration for future use.  \n",
    "\n",
    "Note: This will take about 15 minutes with 10 epochs in the fit function and 30 minutes with 20 epochs so be prepared!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL TRAINING\n",
    "\n",
    "# Start a timer\n",
    "start = time.time()\n",
    "\n",
    "nodes = 32\n",
    "dense_layer = 0\n",
    "\n",
    "# Establish unique name of the model\n",
    "NAME = f\"{1}-conv-{nodes}-nodes-{dense_layer}-dense-{int(time.time())}\"\n",
    "print(NAME)\n",
    "\n",
    "# Instantiate model\n",
    "model = Sequential()\n",
    "\n",
    "# 1 Convolutional Layer - add convolutional layer with filter matrix size 3x3\n",
    "model.add(Conv2D(filters = nodes, kernel_size = (3, 3), input_shape=(128,128, 3)))\n",
    "model.add(Activation('relu'))                   # Rectified linear unit activation function\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))       # Creates \"pooled\" 2x2 matrix of max values\n",
    "model.add(Flatten())                            # Flattens 2D layer to 1D to be passed into next layers\n",
    "\n",
    "# Loop through adding dense layers according to dense_layer\n",
    "for _ in range(dense_layer):\n",
    "    model.add(Dense(nodes))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "# Output Layer\n",
    "model.add(Dense(3)) # 3 output nods for each classification\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# Tensorboard Callbacks - save the logs to the logdir directory\n",
    "tensorboard = TensorBoard(log_dir=logdir + f\"logs/{NAME}\",histogram_freq=1,embeddings_freq=1,\n",
    "                          write_graph=True)\n",
    "\n",
    "# Compile Model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'],\n",
    "              )\n",
    "\n",
    "# Fit model\n",
    "model.fit(train_generator,\n",
    "          epochs=20,\n",
    "          validation_data = validation_generator,\n",
    "#           callbacks=[tensorboard],\n",
    "         ) \n",
    "\n",
    "# Save model\n",
    "model.save(models_dir + f'{NAME}.h5')\n",
    "\n",
    "# Stop timer\n",
    "finish = str(round(time.time()-start,5))\n",
    "print('Time Elapsed:', finish, 'seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3: Model Evaluation\n",
    "In this section we will be analyzing the individual model performances using the Tensorflow callback Tensorboard.  \n",
    "Once your 4 models have trained, open up the command prompt on your computer (either anaconda or cmd). Navigate to the folder you titled \"callbacks\" above   (for example `cd Downloads/callbacks`).\n",
    "\n",
    "Then, run this command:  \n",
    "`tensorboard --logdir=logs/ --host=localhost`\n",
    "\n",
    "At the end of all of the lines printed to the console will be a line that says something like:   \n",
    "`TensorBoard 1.14.0 at http://localhost:6006/ (Press CTRL+C to quit)`\n",
    "\n",
    "Open up the link (`http://localhost:6006/`) and take a look around. Make sure you toggle on all the model trains (you can filter only validation plots there as well) and take a look at the final validation loss for each model. Which preforms best? Which was worst?  \n",
    "\n",
    "Report the accuracy of the best model and load the model using `tensorflow.keras.models.load_model` and the h5 file you saved above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL EVALUATION\n",
    "\n",
    "# -- load model here with load_model() and save it to a variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 4: Model Prediction\n",
    "With your loaded model, make a prediction the photos found in this folder:  \n",
    "- Test: https://drive.google.com/drive/folders/1cqwucUf5O1IoHhUOakjfE61-MFPAgZxC?usp=sharing  \n",
    "\n",
    "Make sure to load the photo, display the photo, and make a prediction. The file name indicates the correct label.\n",
    "\n",
    "#### Hints:\n",
    "- Load the image using tensorflow's image api: `from tensorflow.keras.preprocessing import image`, be sure to set the target_size to (128,128)\n",
    "- Convert the image to an array using `image.img_to_array`\n",
    "- Scale the image by dividing the image array by 255\n",
    "- Expand the dimensions using `np.expand_dims`\n",
    "- Remember that the `model.predict` function returns an array of probabilities for each classification. Find which index has the highest probability and compare that to the classification array (`classes = ['Gravel', 'Sand', 'Silt']`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL PREDICTION\n",
    "\n",
    "# View Image\n",
    "# -- plot the image\n",
    "\n",
    "# Format for model\n",
    "# -- load image using tensorflow.keras.preprocessing.image API\n",
    "# -- convert to an array using image.img_to_array\n",
    "# -- scale the image by dividing the image array by 255\n",
    "# -- expand the array dimensions using np.expand_dims\n",
    "\n",
    "# Make predictions\n",
    "# -- assign array \"classes\" as shown above\n",
    "# -- use model.predict to generate probability array\n",
    "# -- find the index with highest probability\n",
    "# -- index the classes array with that highest probability\n",
    "# -- print out the classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How did the model perform? Choose 1 photo that was misclassified and give some potential reasons why it was incorrect. Then, talk about some ways that you could improve the model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
